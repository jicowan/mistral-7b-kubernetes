# AWS Deep Learning Container for vLLM + Mistral 7B
# Using AWS PyTorch Inference DLC with CUDA support
FROM 763104351884.dkr.ecr.us-west-2.amazonaws.com/pytorch-inference:2.1.0-gpu-py310-cu121-ubuntu20.04-ec2

# Set environment variables
ENV PYTHONUNBUFFERED=1
ENV CUDA_HOME=/usr/local/cuda
ENV PATH=${CUDA_HOME}/bin:${PATH}
ENV LD_LIBRARY_PATH=${CUDA_HOME}/lib64:${LD_LIBRARY_PATH}

# AWS DLC already includes:
# - PyTorch 2.1.0 with CUDA 12.1
# - Python 3.10
# - CUDA toolkit
# - cuDNN
# - NCCL
# - Basic system dependencies

# Install additional system dependencies not in DLC
RUN apt-get update && apt-get install -y \
    git \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Upgrade pip (DLC may have older version)
RUN pip install --upgrade pip

# Install vLLM (compatible with PyTorch 2.1.0)
RUN pip install vllm==0.4.2

# Install additional dependencies for our server
RUN pip install \
    fastapi==0.104.1 \
    uvicorn[standard]==0.24.0 \
    pydantic==2.5.0 \
    transformers==4.36.2 \
    accelerate==0.24.1 \
    sentencepiece==0.1.99

# Create app directory
WORKDIR /app

# Copy application files
COPY vllm_server.py .
COPY requirements.txt .

# Expose port
EXPOSE 8000

# Health check
HEALTHCHECK --interval=30s --timeout=30s --start-period=60s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

# Set optimal environment variables for AWS DLC
ENV NCCL_DEBUG=INFO
ENV NCCL_SOCKET_IFNAME=^docker0,lo
ENV CUDA_LAUNCH_BLOCKING=0

# Run the application
CMD ["python", "vllm_server.py"]
