# tp_degree Verification and Updates

## Verification Complete âœ…

I've verified and updated both neuron_server.py files to ensure `tp_degree` is properly set to 2 for tensor parallelism across both Neuron cores.

## Changes Applied âœ…

### **1. Added TENSOR_PARALLEL_SIZE Environment Variable**

#### **Before**:
```python
NEURON_CORES = int(os.getenv("NEURON_CORES", "2"))
# tp_degree=NEURON_CORES (indirect)
```

#### **After**:
```python
NEURON_CORES = int(os.getenv("NEURON_CORES", "2"))
TENSOR_PARALLEL_SIZE = int(os.getenv("TENSOR_PARALLEL_SIZE", str(NEURON_CORES)))
# tp_degree=TENSOR_PARALLEL_SIZE (explicit)
```

### **2. Updated tp_degree Parameter**

#### **Before**:
```python
model = MistralForCausalLM.from_pretrained(
    MODEL_NAME,
    tp_degree=NEURON_CORES,  # Indirect reference
    ...
)
```

#### **After**:
```python
model = MistralForCausalLM.from_pretrained(
    MODEL_NAME,
    tp_degree=TENSOR_PARALLEL_SIZE,  # Explicit tensor parallel size
    ...
)
```

### **3. Enhanced Logging**

#### **Before**:
```python
logger.info(f"   - Tensor parallel degree: {NEURON_CORES}")
```

#### **After**:
```python
logger.info(f"   - Tensor parallel degree: {TENSOR_PARALLEL_SIZE}")
logger.info(f"   - Neuron cores: {NEURON_CORES}")
```

## Configuration Flow âœ…

### **Environment Variables â†’ Code**:
```yaml
# Kubernetes deployment
env:
- name: NEURON_CORES
  value: "2"
- name: TENSOR_PARALLEL_SIZE
  value: "2"
```

```python
# neuron_server.py
NEURON_CORES = int(os.getenv("NEURON_CORES", "2"))                    # = 2
TENSOR_PARALLEL_SIZE = int(os.getenv("TENSOR_PARALLEL_SIZE", "2"))    # = 2

# transformers-neuronx model loading
model = MistralForCausalLM.from_pretrained(
    MODEL_NAME,
    tp_degree=TENSOR_PARALLEL_SIZE,  # = 2 (explicit)
    ...
)
```

## Verification Results âœ…

### **Both Files Now Have**:
- âœ… **TENSOR_PARALLEL_SIZE** environment variable support
- âœ… **tp_degree=TENSOR_PARALLEL_SIZE** (explicit value of 2)
- âœ… **Enhanced logging** showing both tensor parallel degree and neuron cores
- âœ… **Consistent configuration** across neuron-dlc and neuron-inferentia

### **Expected Values**:
- **NEURON_CORES**: 2 (number of physical cores)
- **TENSOR_PARALLEL_SIZE**: 2 (parallelism degree)
- **tp_degree**: 2 (passed to transformers-neuronx)

## Expected Behavior âœ…

### **Startup Logs**:
```
ðŸš€ Loading Mistral model with transformers-neuronx optimization...
ðŸ”§ Initializing optimized Mistral model for Neuron...
âœ… Optimized Neuron model loaded successfully
ðŸ“Š Model configuration:
   - Batch size: 1
   - Tensor parallel degree: 2
   - Neuron cores: 2
   - Context length: 4096
   - Precision: float32
```

### **Memory Distribution**:
- **Core 0**: ~8GB (half of model)
- **Core 1**: ~8GB (half of model)
- **Total**: ~16GB distributed across both cores
- **Per-core limit**: 16GB (not exceeded)

## Benefits âœ…

### **1. Explicit Configuration**
- âœ… **Clear separation** between physical cores and parallelism degree
- âœ… **Explicit tp_degree setting** removes ambiguity
- âœ… **Environment variable control** for easy tuning

### **2. Better Debugging**
- âœ… **Detailed logging** shows exact configuration
- âœ… **Clear distinction** between cores and parallelism
- âœ… **Easy verification** of tensor parallel settings

### **3. Consistency**
- âœ… **Both images identical** configuration approach
- âœ… **Environment variables aligned** with Kubernetes deployment
- âœ… **Code matches deployment** configuration

### **4. Memory Optimization**
- âœ… **Model split across 2 cores** (8GB each)
- âœ… **Avoids 16GB per-core limit** that was causing failures
- âœ… **Access to full 32GB** Neuron memory (16GB Ã— 2 cores)

## Testing Verification

### **1. Check Environment Variables**:
```bash
kubectl exec -it <pod-name> -- env | grep -E "(NEURON_CORES|TENSOR_PARALLEL_SIZE)"
# Should show:
# NEURON_CORES=2
# TENSOR_PARALLEL_SIZE=2
```

### **2. Check Startup Logs**:
```bash
kubectl logs -l app=neuron-mistral-7b -f | grep "Tensor parallel degree"
# Should show:
# - Tensor parallel degree: 2
```

### **3. Verify Memory Distribution**:
```bash
kubectl exec -it <pod-name> -- neuron-top
# Should show usage distributed across both cores
```

## Summary âœ…

The tp_degree verification and updates ensure:

1. âœ… **tp_degree is explicitly set to 2** in both neuron_server.py files
2. âœ… **TENSOR_PARALLEL_SIZE environment variable** provides explicit control
3. âœ… **Enhanced logging** shows exact tensor parallelism configuration
4. âœ… **Consistent configuration** across both images
5. âœ… **Memory distribution** across both 16GB Neuron cores

**ðŸŽ‰ Both images now have verified tp_degree=2 configuration that should properly distribute the Mistral 7B model across both Neuron cores, avoiding the 15.938GB single-core memory limit!**
